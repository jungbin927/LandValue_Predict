{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn4hof6sezAb"
      },
      "source": [
        "### ÏΩîÎû© Îã§Ïö¥Î°úÎìú"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFxjW1iHWTCa",
        "outputId": "a09272de-1866-4623-b35e-5a42488e22b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/yura52/rtdl.git\n",
            "  Cloning https://github.com/yura52/rtdl.git to /tmp/pip-req-build-z037suie\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/yura52/rtdl.git /tmp/pip-req-build-z037suie\n",
            "  Resolved https://github.com/yura52/rtdl.git to commit bdc2fe52e0c28d0d15a3cf7d99ef94a452f23253\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from rtdl==0.0.14.dev7) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl==0.0.14.dev7) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl==0.0.14.dev7) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl==0.0.14.dev7) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl==0.0.14.dev7) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl==0.0.14.dev7) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=1.8->rtdl==0.0.14.dev7)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=1.8->rtdl==0.0.14.dev7)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=1.8->rtdl==0.0.14.dev7)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=1.8->rtdl==0.0.14.dev7)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=1.8->rtdl==0.0.14.dev7)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=1.8->rtdl==0.0.14.dev7)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=1.8->rtdl==0.0.14.dev7)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=1.8->rtdl==0.0.14.dev7)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=1.8->rtdl==0.0.14.dev7)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl==0.0.14.dev7) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl==0.0.14.dev7) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl==0.0.14.dev7) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=1.8->rtdl==0.0.14.dev7)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl==0.0.14.dev7) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl==0.0.14.dev7) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=1.8->rtdl==0.0.14.dev7) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=1.8->rtdl==0.0.14.dev7) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rtdl\n",
            "  Building wheel for rtdl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rtdl: filename=rtdl-0.0.14.dev7-py3-none-any.whl size=27164 sha256=4f2298eaac123f938b6399d22124195c388d4caf34b0368c933b106be352d6e2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tqpu7hhw/wheels/7f/7a/5c/88c72feb54756a9ded3401a0829d8be66129d21faf4e01224a\n",
            "Successfully built rtdl\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, rtdl\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rtdl-0.0.14.dev7\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.1 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ],
      "source": [
        "! pip install git+https://github.com/yura52/rtdl.git\n",
        "! pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5R_YoSAezAj"
      },
      "source": [
        "### ÎùºÏù¥Î∏åÎü¨Î¶¨ Ìò∏Ï∂ú"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXumz1YKYDcu",
        "outputId": "06558b46-9b00-4afa-d2d5-ef237a2f307b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìå ÏÇ¨Ïö© ÎîîÎ∞îÏù¥Ïä§: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ‚úÖ ColabÏóêÏÑú GPU ÏÇ¨Ïö© Í∞ÄÎä• Ïó¨Î∂Ä ÌôïÏù∏\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"üìå ÏÇ¨Ïö© ÎîîÎ∞îÏù¥Ïä§:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bKOC-TWZWge5"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ Ï†ÄÏû•Îêú ÌÖêÏÑú Îç∞Ïù¥ÌÑ∞ Î°úÎìú (.pkl ÌååÏùº)\n",
        "import pickle\n",
        "\n",
        "with open(\"VIF_split_data_ft_transformer.pkl\", \"rb\") as f:\n",
        "    X_train_tensor, X_valid_tensor, X_test_tensor, y_train_tensor, y_valid_tensor, y_test_tensor = pickle.load(f)\n",
        "\n",
        "# ‚úÖ GPUÎ°ú Îç∞Ïù¥ÌÑ∞ Ïù¥Îèô\n",
        "X_train_tensor = X_train_tensor.to(device)\n",
        "X_valid_tensor = X_valid_tensor.to(device)\n",
        "X_test_tensor = X_test_tensor.to(device)\n",
        "y_train_tensor = y_train_tensor.to(device)\n",
        "y_valid_tensor = y_valid_tensor.to(device)\n",
        "y_test_tensor = y_test_tensor.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y27yxi8CXUkj",
        "outputId": "b13a3457-e86a-45a1-ab51-1da3319834bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìå Î≤îÏ£ºÌòï Î≥ÄÏàò Ïù∏Îç±Ïä§: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n"
          ]
        }
      ],
      "source": [
        "# ‚úÖ Î≤îÏ£ºÌòï Î≥ÄÏàò Ïù∏Îç±Ïä§ Î∞è Í∞í Îß§Ìïë\n",
        "X_train_df = pd.DataFrame(X_train_tensor.cpu().numpy())\n",
        "categorical_indices = [] # Î≤îÏ£ºÌòï Î≥ÄÏàò Ï†ÄÏû•\n",
        "category_value_map = {}\n",
        "# ÎùºÎ≤® Ïù∏ÏΩîÎî©ÎêòÏñ¥ ÏûàÎäî Îç∞Ïù¥ÌÑ∞Ïù¥Í∏∞Ïóê int, floatÌòïÌÉú, Í∑∏Î¶¨Í≥† Í∞íÏù¥ 20Í∞ú Ïù¥ÌïòÏù∏ Í≤ÉÏùÑ Î≤îÏ£ºÌòï\n",
        "# Î≥ÄÏàòÎ°ú Ï†ÄÏû•\n",
        "for idx in X_train_df.columns:\n",
        "    unique_values = X_train_df[idx].value_counts().index.tolist()\n",
        "    if X_train_df[idx].dtype in ['int32', 'int64', 'float32', 'float64'] and len(unique_values) <= 20:\n",
        "        categorical_indices.append(idx)\n",
        "        category_value_map[idx] = unique_values\n",
        "\n",
        "print(\"üìå Î≤îÏ£ºÌòï Î≥ÄÏàò Ïù∏Îç±Ïä§:\", categorical_indices)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-g4QDmJJYUPx"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "# ‚úÖ Ï†ÅÎåÄÏ†Å Í≥µÍ≤© Ìï®Ïàò\n",
        "# Î≤îÏ£ºÌòï Í∞íÏùò Î¨¥ÏûëÏúÑ Î≥ÄÌôî\n",
        "def category_switch_attack_tensor(X_tensor, categorical_indices, category_value_map, num_switches=1, random_state=42):\n",
        "    np.random.seed(random_state)\n",
        "    X_np = X_tensor.cpu().numpy()\n",
        "    X_adv = deepcopy(X_np)\n",
        "\n",
        "    for i in range(X_adv.shape[0]):\n",
        "        selected = np.random.choice(categorical_indices, size=min(num_switches, len(categorical_indices)), replace=False)\n",
        "        for col in selected:\n",
        "            current_val = X_adv[i, col]\n",
        "            possible = list(set(category_value_map[col]) - {current_val})\n",
        "            if possible:\n",
        "                X_adv[i, col] = np.random.choice(possible)\n",
        "\n",
        "    return torch.tensor(X_adv, dtype=X_tensor.dtype).to(X_tensor.device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BXO3yM0wYZ-9"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ Ïä§ÏúÑÏπ≠ 1Í∞ú Ï†ÅÏö©\n",
        "X_train_adv = category_switch_attack_tensor(X_train_tensor, categorical_indices, category_value_map, num_switches=1)\n",
        "X_valid_adv = category_switch_attack_tensor(X_valid_tensor, categorical_indices, category_value_map, num_switches=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_Ya5l1QXfHbC"
      },
      "outputs": [],
      "source": [
        "with open(\"ADV&VIF_split_data_fn_transformer.pkl\", \"wb\") as f:\n",
        "        pickle.dump((X_train_adv, X_valid_adv, X_test_tensor,\n",
        "                 y_train_tensor, y_valid_tensor, y_test_tensor), f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhmWBG0nZqkh",
        "outputId": "e384ae6c-340a-43b1-b588-d2c933f2a00d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-02 16:09:06,361] A new study created in memory with name: no-name-deb39b80-af87-4f81-b910-a70f99f4b8b3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-02 16:18:41,755] Trial 0 finished with value: 0.00928332656621933 and parameters: {'d_token': 64, 'n_blocks': 6, 'n_heads': 4, 'dropout': 0.18461083843716591, 'ffn_d_hidden': 512}. Best is trial 0 with value: 0.00928332656621933.\n",
            "[I 2025-06-02 16:24:31,457] Trial 1 finished with value: 0.009379222057759762 and parameters: {'d_token': 32, 'n_blocks': 5, 'n_heads': 8, 'dropout': 0.32337833611407996, 'ffn_d_hidden': 512}. Best is trial 0 with value: 0.00928332656621933.\n",
            "[I 2025-06-02 16:30:32,199] Trial 2 finished with value: 0.009330421686172485 and parameters: {'d_token': 64, 'n_blocks': 4, 'n_heads': 8, 'dropout': 0.25255728504765235, 'ffn_d_hidden': 512}. Best is trial 0 with value: 0.00928332656621933.\n",
            "[I 2025-06-02 16:42:37,939] Trial 3 finished with value: 0.009392506442964077 and parameters: {'d_token': 128, 'n_blocks': 6, 'n_heads': 4, 'dropout': 0.4874156178051334, 'ffn_d_hidden': 256}. Best is trial 0 with value: 0.00928332656621933.\n",
            "[I 2025-06-02 16:50:04,718] Trial 4 finished with value: 0.009306511841714382 and parameters: {'d_token': 32, 'n_blocks': 5, 'n_heads': 8, 'dropout': 0.31943732409504705, 'ffn_d_hidden': 512}. Best is trial 0 with value: 0.00928332656621933.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial:\n",
            "FrozenTrial(number=0, state=1, values=[0.00928332656621933], datetime_start=datetime.datetime(2025, 6, 2, 16, 9, 6, 362038), datetime_complete=datetime.datetime(2025, 6, 2, 16, 18, 41, 755406), params={'d_token': 64, 'n_blocks': 6, 'n_heads': 4, 'dropout': 0.18461083843716591, 'ffn_d_hidden': 512}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'d_token': CategoricalDistribution(choices=(32, 64, 128)), 'n_blocks': IntDistribution(high=6, log=False, low=2, step=1), 'n_heads': CategoricalDistribution(choices=(2, 4, 8)), 'dropout': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'ffn_d_hidden': CategoricalDistribution(choices=(128, 256, 512))}, trial_id=0, value=None)\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from rtdl import FTTransformer\n",
        "import optuna\n",
        "\n",
        "# ‚úÖ GPU ÏÑ§Ï†ï\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ‚úÖ Î™®Îì† Î≥ÄÏàòÎäî Î≤îÏ£ºÌòï (ÎùºÎ≤® Ïù∏ÏΩîÎî© ÏÉÅÌÉú)\n",
        "cat_indices = list(range(X_train_adv.shape[1]))  \n",
        "cat_cardinalities = [\n",
        "    int(X_train_adv[:, i].max().item()) + 1     \n",
        "    for i in cat_indices\n",
        "]\n",
        "\n",
        "# ‚úÖ Î≤îÏ£ºÌòïÎßå Î∂ÑÎ¶¨ÌïòÎäî Ìï®Ïàò\n",
        "def split_features(X_tensor):\n",
        "    x_cat = X_tensor[:, cat_indices]\n",
        "    return None, x_cat  # x_numÏùÄ ÏóÜÏùå\n",
        "\n",
        "# ‚úÖ DataLoader\n",
        "train_dataset = TensorDataset(X_train_adv, y_train_tensor)  \n",
        "valid_dataset = TensorDataset(X_valid_adv, y_valid_tensor)   \n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=512, shuffle=False)\n",
        "\n",
        "# ‚úÖ Optuna Î™©Ï†Å Ìï®Ïàò\n",
        "def objective(trial):\n",
        "    d_token = trial.suggest_categorical(\"d_token\", [32, 64, 128])\n",
        "    n_blocks = trial.suggest_int(\"n_blocks\", 2, 6)\n",
        "    n_heads = trial.suggest_categorical(\"n_heads\", [2, 4, 8])\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
        "    ffn_d_hidden = trial.suggest_categorical(\"ffn_d_hidden\", [128, 256, 512])\n",
        "\n",
        "    model = FTTransformer.make_baseline(\n",
        "        n_num_features=0,                      # ÏàòÏπòÌòï ÏóÜÏùå\n",
        "        cat_cardinalities=cat_cardinalities,   # Î≤îÏ£ºÌòï ÌÅ¥ÎûòÏä§ Ïàò ÏßÄÏ†ï\n",
        "        d_token=d_token,\n",
        "        n_blocks=n_blocks,\n",
        "        attention_dropout=dropout,\n",
        "        ffn_d_hidden=ffn_d_hidden,\n",
        "        ffn_dropout=dropout,\n",
        "        residual_dropout=dropout,\n",
        "        d_out=1\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    best_rmse = float(\"inf\")\n",
        "    patience = 10\n",
        "    trigger_times = 0\n",
        "\n",
        "    for epoch in range(80):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            _, x_cat = split_features(xb)\n",
        "            pred = model(None, x_cat.to(device).long())\n",
        "            loss = loss_fn(pred, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Í≤ÄÏ¶ù\n",
        "        model.eval()\n",
        "        preds = []\n",
        "        with torch.no_grad():\n",
        "            for xb, _ in valid_loader:\n",
        "                xb = xb.to(device)\n",
        "                _, x_cat = split_features(xb)\n",
        "                pred = model(None, x_cat.to(device).long())\n",
        "                preds.append(pred.cpu().numpy())\n",
        "\n",
        "        preds = np.vstack(preds)\n",
        "        rmse = np.sqrt(np.mean((y_valid_tensor.cpu().numpy() - preds) ** 2))   # ‚¨ÖÔ∏è GPU Í≥†Î†§Ìï¥ .cpu()\n",
        "\n",
        "        if rmse < best_rmse:\n",
        "            best_rmse = rmse\n",
        "            trigger_times = 0\n",
        "        else:\n",
        "            trigger_times += 1\n",
        "            if trigger_times >= patience:\n",
        "                break\n",
        "\n",
        "    return best_rmse\n",
        "\n",
        "# ‚úÖ Optuna Ïã§Ìñâ\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=5)\n",
        "\n",
        "# ‚úÖ Í≤∞Í≥º ÌôïÏù∏\n",
        "print(\"Best trial:\")\n",
        "print(study.best_trial)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7z-x6nijauP"
      },
      "outputs": [],
      "source": [
        "fixed_params = {\n",
        "    \"d_token\": 64,\n",
        "    \"n_blocks\": 6,\n",
        "    \"n_heads\": 4,\n",
        "    \"dropout\": 0.18461083843716591,\n",
        "    \"ffn_d_hidden\": 512\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-wW9KniZvvc",
        "outputId": "d61b3e11-d539-42d7-80fa-46fabe522359"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-02 16:59:44,131] A new study created in memory with name: no-name-f8c9dcca-ba3f-470c-a1d1-790b04a58b2b\n",
            "[I 2025-06-02 17:16:02,303] Trial 0 finished with value: 0.009363311342895031 and parameters: {'lr': 0.0011551468095722312, 'weight_decay': 0.009657899108623313, 'batch_size': 2048}. Best is trial 0 with value: 0.009363311342895031.\n",
            "[I 2025-06-02 17:28:25,272] Trial 1 finished with value: 0.009597341530025005 and parameters: {'lr': 0.0014770590058152014, 'weight_decay': 0.00478996500029039, 'batch_size': 2048}. Best is trial 0 with value: 0.009363311342895031.\n",
            "[I 2025-06-02 17:42:35,202] Trial 2 finished with value: 0.009553882293403149 and parameters: {'lr': 0.00028838988803365806, 'weight_decay': 0.006318059154128248, 'batch_size': 2048}. Best is trial 0 with value: 0.009363311342895031.\n",
            "[I 2025-06-02 18:07:45,014] Trial 3 finished with value: 0.009289581328630447 and parameters: {'lr': 0.00022610258666503442, 'weight_decay': 0.009544484639969084, 'batch_size': 2048}. Best is trial 3 with value: 0.009289581328630447.\n",
            "[I 2025-06-02 18:18:42,889] Trial 4 finished with value: 0.010961568914353848 and parameters: {'lr': 0.00043474400743196963, 'weight_decay': 0.009984061610139611, 'batch_size': 2048}. Best is trial 3 with value: 0.009289581328630447.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial:\n",
            "FrozenTrial(number=3, state=1, values=[0.009289581328630447], datetime_start=datetime.datetime(2025, 6, 2, 17, 42, 35, 203604), datetime_complete=datetime.datetime(2025, 6, 2, 18, 7, 45, 14064), params={'lr': 0.00022610258666503442, 'weight_decay': 0.009544484639969084, 'batch_size': 2048}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'lr': FloatDistribution(high=0.003, log=True, low=0.0001, step=None), 'weight_decay': FloatDistribution(high=0.01, log=False, low=0.0, step=None), 'batch_size': CategoricalDistribution(choices=(512, 1024, 2048))}, trial_id=3, value=None)\n"
          ]
        }
      ],
      "source": [
        "def hparam_objective(trial):\n",
        "    # ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏÉòÌîåÎßÅ\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 3e-3, log=True)\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 0.0, 1e-2)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [512, 1024, 2048])\n",
        "\n",
        "    # Î≤îÏ£ºÌòï Î≥ÄÏàò Ïù∏Îç±Ïä§ Î∞è cardinalities (Í≥†Ï†ï)\n",
        "    cat_indices = list(range(X_train_adv.shape[1]))\n",
        "    cat_cardinalities = [\n",
        "        int(X_train_adv[:, i].max().item()) + 1\n",
        "        for i in cat_indices\n",
        "    ]\n",
        "\n",
        "    # Î™®Îç∏ Ï†ïÏùò\n",
        "    model = FTTransformer.make_baseline(\n",
        "        n_num_features=0,\n",
        "        cat_cardinalities=cat_cardinalities,\n",
        "        d_token=fixed_params[\"d_token\"],\n",
        "        n_blocks=fixed_params[\"n_blocks\"],\n",
        "        attention_dropout=fixed_params[\"dropout\"],\n",
        "        ffn_d_hidden=fixed_params[\"ffn_d_hidden\"],\n",
        "        ffn_dropout=fixed_params[\"dropout\"],\n",
        "        residual_dropout=fixed_params[\"dropout\"],\n",
        "        d_out=1\n",
        "    ).to(device)\n",
        "\n",
        "    # ÏòµÌã∞ÎßàÏù¥Ï†Ä\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    # Î∞∞Ïπò ÌÅ¨Í∏∞Ïóê Îî∞Î•∏ DataLoader\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=False)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, pin_memory=False)\n",
        "\n",
        "    # ÌïôÏäµ Î£®ÌîÑ\n",
        "    best_rmse = float(\"inf\")\n",
        "    patience = 10\n",
        "    trigger_times = 0\n",
        "\n",
        "    for epoch in range(80):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            x_cat = xb[:, cat_indices].long()\n",
        "            pred = model(None, x_cat)\n",
        "            loss = loss_fn(pred, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Í≤ÄÏ¶ù\n",
        "        model.eval()\n",
        "        preds = []\n",
        "        with torch.no_grad():\n",
        "            for xb, _ in valid_loader:\n",
        "                xb = xb.to(device)\n",
        "                x_cat = xb[:, cat_indices].long()\n",
        "                pred = model(None, x_cat)\n",
        "                preds.append(pred.cpu().numpy())\n",
        "\n",
        "        preds = np.vstack(preds)\n",
        "        rmse = np.sqrt(np.mean((y_valid_tensor.cpu().numpy() - preds) ** 2))\n",
        "\n",
        "\n",
        "        if rmse < best_rmse:\n",
        "            best_rmse = rmse\n",
        "            trigger_times = 0\n",
        "        else:\n",
        "            trigger_times += 1\n",
        "            if trigger_times >= patience:\n",
        "                break\n",
        "\n",
        "    return best_rmse\n",
        "\n",
        "study_hparam = optuna.create_study(direction=\"minimize\")\n",
        "study_hparam.optimize(hparam_objective, n_trials=5)  \n",
        "\n",
        "print(\"Best trial:\")\n",
        "print(study_hparam.best_trial)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "fixed_params = {\n",
        "    \"d_token\": 64,\n",
        "    \"n_blocks\": 4,\n",
        "    \"n_heads\": 4,\n",
        "    \"dropout\": 0.1971837206675287,\n",
        "    \"ffn_d_hidden\": 512\n",
        "}\n",
        "\n",
        "best_hparam = {\n",
        "    \"lr\": 0.00022610258666503442,\n",
        "    \"weight_decay\": 0.009544484639969084,\n",
        "    \"batch_size\": 2048\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBKbr0i_lYhJ",
        "outputId": "066ea993-1138-4b6d-a8c7-ccc96ed70f45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/1000] Loss: 1.7908\n",
            "[2/1000] Loss: 0.1813\n",
            "[3/1000] Loss: 0.0939\n",
            "[4/1000] Loss: 0.0632\n",
            "[5/1000] Loss: 0.0513\n",
            "[6/1000] Loss: 0.0462\n",
            "[7/1000] Loss: 0.0424\n",
            "[8/1000] Loss: 0.0394\n",
            "[9/1000] Loss: 0.0365\n",
            "[10/1000] Loss: 0.0336\n",
            "[11/1000] Loss: 0.0311\n",
            "[12/1000] Loss: 0.0296\n",
            "[13/1000] Loss: 0.0286\n",
            "[14/1000] Loss: 0.0274\n",
            "[15/1000] Loss: 0.0267\n",
            "[16/1000] Loss: 0.0262\n",
            "[17/1000] Loss: 0.0258\n",
            "[18/1000] Loss: 0.0254\n",
            "[19/1000] Loss: 0.0251\n",
            "[20/1000] Loss: 0.0247\n",
            "[21/1000] Loss: 0.0241\n",
            "[22/1000] Loss: 0.0241\n",
            "[23/1000] Loss: 0.0237\n",
            "[24/1000] Loss: 0.0233\n",
            "[25/1000] Loss: 0.0230\n",
            "[26/1000] Loss: 0.0227\n",
            "[27/1000] Loss: 0.0225\n",
            "[28/1000] Loss: 0.0223\n",
            "[29/1000] Loss: 0.0220\n",
            "[30/1000] Loss: 0.0218\n",
            "[31/1000] Loss: 0.0216\n",
            "[32/1000] Loss: 0.0214\n",
            "[33/1000] Loss: 0.0213\n",
            "[34/1000] Loss: 0.0210\n",
            "[35/1000] Loss: 0.0209\n",
            "[36/1000] Loss: 0.0203\n",
            "[37/1000] Loss: 0.0206\n",
            "[38/1000] Loss: 0.0202\n",
            "[39/1000] Loss: 0.0202\n",
            "[40/1000] Loss: 0.0200\n",
            "[41/1000] Loss: 0.0200\n",
            "[42/1000] Loss: 0.0196\n",
            "[43/1000] Loss: 0.0196\n",
            "[44/1000] Loss: 0.0194\n",
            "[45/1000] Loss: 0.0194\n",
            "[46/1000] Loss: 0.0191\n",
            "[47/1000] Loss: 0.0191\n",
            "[48/1000] Loss: 0.0190\n",
            "[49/1000] Loss: 0.0191\n",
            "[50/1000] Loss: 0.0190\n",
            "[51/1000] Loss: 0.0190\n",
            "[52/1000] Loss: 0.0187\n",
            "[53/1000] Loss: 0.0186\n",
            "[54/1000] Loss: 0.0186\n",
            "[55/1000] Loss: 0.0186\n",
            "[56/1000] Loss: 0.0186\n",
            "[57/1000] Loss: 0.0185\n",
            "[58/1000] Loss: 0.0183\n",
            "[59/1000] Loss: 0.0182\n",
            "[60/1000] Loss: 0.0182\n",
            "[61/1000] Loss: 0.0182\n",
            "[62/1000] Loss: 0.0183\n",
            "[63/1000] Loss: 0.0181\n",
            "[64/1000] Loss: 0.0179\n",
            "[65/1000] Loss: 0.0178\n",
            "[66/1000] Loss: 0.0179\n",
            "[67/1000] Loss: 0.0177\n",
            "[68/1000] Loss: 0.0178\n",
            "[69/1000] Loss: 0.0178\n",
            "[70/1000] Loss: 0.0175\n",
            "[71/1000] Loss: 0.0175\n",
            "[72/1000] Loss: 0.0175\n",
            "[73/1000] Loss: 0.0175\n",
            "[74/1000] Loss: 0.0172\n",
            "[75/1000] Loss: 0.0172\n",
            "[76/1000] Loss: 0.0174\n",
            "[77/1000] Loss: 0.0172\n",
            "[78/1000] Loss: 0.0172\n",
            "[79/1000] Loss: 0.0173\n",
            "[80/1000] Loss: 0.0171\n",
            "[81/1000] Loss: 0.0171\n",
            "[82/1000] Loss: 0.0168\n",
            "[83/1000] Loss: 0.0170\n",
            "[84/1000] Loss: 0.0169\n",
            "[85/1000] Loss: 0.0167\n",
            "[86/1000] Loss: 0.0168\n",
            "[87/1000] Loss: 0.0169\n",
            "[88/1000] Loss: 0.0166\n",
            "[89/1000] Loss: 0.0166\n",
            "[90/1000] Loss: 0.0167\n",
            "[91/1000] Loss: 0.0165\n",
            "[92/1000] Loss: 0.0165\n",
            "[93/1000] Loss: 0.0164\n",
            "[94/1000] Loss: 0.0165\n",
            "[95/1000] Loss: 0.0164\n",
            "[96/1000] Loss: 0.0164\n",
            "[97/1000] Loss: 0.0163\n",
            "[98/1000] Loss: 0.0161\n",
            "[99/1000] Loss: 0.0163\n",
            "[100/1000] Loss: 0.0158\n",
            "\n",
            "‚úÖ ÏµúÏ¢Ö RMSE: 1,623,371.64\n",
            "‚úÖ ÏµúÏ¢Ö R¬≤: 0.63123\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from rtdl import FTTransformer\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# ‚úÖ ÎîîÎ∞îÏù¥Ïä§ ÏÑ§Ï†ï\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ‚úÖ Îç∞Ïù¥ÌÑ∞ Î≥ëÌï© (train + valid)\n",
        "X_final_tensor = torch.cat([X_train_adv, X_valid_adv], dim=0)\n",
        "y_final_tensor = torch.cat([y_train_tensor, y_valid_tensor], dim=0)\n",
        "\n",
        "train_dataset = TensorDataset(X_final_tensor, y_final_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=best_hparam[\"batch_size\"], shuffle=True, pin_memory=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=best_hparam[\"batch_size\"], shuffle=False, pin_memory=False)\n",
        "\n",
        "# ‚úÖ Î≤îÏ£ºÌòï Ïù∏Îç±Ïä§ Î∞è cardinalities Í≥ÑÏÇ∞\n",
        "cat_indices = list(range(X_final_tensor.shape[1]))\n",
        "cat_cardinalities = [\n",
        "    int(X_final_tensor[:, i].max().item()) + 1\n",
        "    for i in cat_indices\n",
        "]\n",
        "\n",
        "# ‚úÖ Î™®Îç∏ Ï†ïÏùò\n",
        "model = FTTransformer.make_baseline(\n",
        "    n_num_features=0,                         \n",
        "    cat_cardinalities=cat_cardinalities,      #  Î≤îÏ£ºÌòï cardinality Í≥ÑÏÇ∞\n",
        "    d_token=fixed_params[\"d_token\"],\n",
        "    n_blocks=fixed_params[\"n_blocks\"],\n",
        "    attention_dropout=fixed_params[\"dropout\"],\n",
        "    ffn_d_hidden=fixed_params[\"ffn_d_hidden\"],\n",
        "    ffn_dropout=fixed_params[\"dropout\"],\n",
        "    residual_dropout=fixed_params[\"dropout\"],\n",
        "    d_out=1\n",
        ").to(device)\n",
        "\n",
        "\n",
        "# ‚úÖ ÌïôÏäµ Ï§ÄÎπÑ\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=best_hparam[\"lr\"], weight_decay=best_hparam[\"weight_decay\"])\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# ‚úÖ ÌïôÏäµ Î£®ÌîÑ\n",
        "model.train()\n",
        "for epoch in range(100):\n",
        "    total_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        x_cat = xb[:, cat_indices].long()\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(None, x_cat)\n",
        "        loss = loss_fn(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"[{epoch+1}/1000] Loss: {total_loss:.4f}\")\n",
        "\n",
        "# ‚úÖ ÌÖåÏä§Ìä∏ÏÖã ÏòàÏ∏°\n",
        "model.eval()\n",
        "preds = []\n",
        "with torch.no_grad():\n",
        "    for xb, _ in test_loader:\n",
        "        xb = xb.to(device)\n",
        "        x_cat = xb[:, cat_indices].long()\n",
        "        pred = model(None, x_cat)\n",
        "        preds.append(pred.cpu().numpy())\n",
        "\n",
        "preds = np.vstack(preds)\n",
        "y_test = y_test_tensor.cpu().numpy()\n",
        "\n",
        "# ‚úÖ Ïó≠Ï†ïÍ∑úÌôî\n",
        "y_min = 216.0\n",
        "y_max = 165300000.0\n",
        "\n",
        "preds_inverse = preds * (y_max - y_min) + y_min\n",
        "y_test_inverse = y_test * (y_max - y_min) + y_min\n",
        "\n",
        "# ‚úÖ ÏÑ±Îä• ÌèâÍ∞Ä\n",
        "mse = mean_squared_error(y_test_inverse, preds_inverse)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test_inverse, preds_inverse)\n",
        "\n",
        "print(f\"\\n‚úÖ ÏµúÏ¢Ö RMSE: {rmse:,.2f}\")\n",
        "print(f\"‚úÖ ÏµúÏ¢Ö R¬≤: {r2:.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9n6-w7p07eMl"
      },
      "outputs": [],
      "source": [
        "torch.save(model, \"ADV_fttransformer_trained.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pI0P_BciezAt",
        "outputId": "34755423-740d-48e6-af98-ef7978a91055"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ÌïúÍ∏Ä Ìè∞Ìä∏ ÏÑ§Ï†ï\n",
        "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# ‚úÖ Îç∞Ïù¥ÌÑ∞\n",
        "labels = ['Í≥µÍ≤© Ï†Ñ', 'Í≥µÍ≤© ÌõÑ']\n",
        "rmse_values = [1545606.65, 1623371.64]\n",
        "r2_values = [0.66571, 0.63123]\n",
        "colors = ['skyblue', 'salmon']  # Í≥µÍ≤© Ï†Ñ/ÌõÑ ÏÉâÏÉÅ ÏßÄÏ†ï\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "\n",
        "# ‚úÖ ÏãúÍ∞ÅÌôî\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# ‚ñ∂ RMSE Í∑∏ÎûòÌîÑ\n",
        "bars1 = axs[0].bar(labels, rmse_values, color=colors)\n",
        "axs[0].set_title('Í≥µÍ≤© Ï†Ñ vs Í≥µÍ≤© ÌõÑ FTTransfer Î™®Îç∏Ïùò RMSE ÎπÑÍµê')\n",
        "axs[0].set_ylabel('RMSE')\n",
        "axs[0].set_ylim(1500000, 1900000)\n",
        "\n",
        "# ‚ñ∂ RMSE ÎßâÎåÄ ÏúÑ Ïà´Ïûê\n",
        "for bar in bars1:\n",
        "    height = bar.get_height()\n",
        "    axs[0].text(bar.get_x() + bar.get_width() / 2, height + 10000, f\"{height:,.0f}\",\n",
        "                ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "# ‚ñ∂ R¬≤ Í∑∏ÎûòÌîÑ\n",
        "bars2 = axs[1].bar(labels, r2_values, color=colors)\n",
        "axs[1].set_title('Í≥µÍ≤© Ï†Ñ vs Í≥µÍ≤© ÌõÑ FTTransfer Î™®Îç∏Ïùò R¬≤ ÎπÑÍµê')\n",
        "axs[1].set_ylabel('R¬≤')\n",
        "axs[1].set_ylim(0.5, 0.8)\n",
        "\n",
        "# ‚ñ∂ R¬≤ ÎßâÎåÄ ÏúÑ Ïà´Ïûê\n",
        "for bar in bars2:\n",
        "    height = bar.get_height()\n",
        "    axs[1].text(bar.get_x() + bar.get_width() / 2, height + 0.01, f\"{height:.3f}\",\n",
        "                ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxjXXZ7HgKal"
      },
      "source": [
        "# Ï∂îÍ∞Ä Î∂ÑÏÑù"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w5jEiNBezAt",
        "outputId": "7f8e382f-dafc-4b68-907a-8c1844ed146a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FTTransformer(\n",
              "  (feature_tokenizer): FeatureTokenizer(\n",
              "    (cat_tokenizer): CategoricalFeatureTokenizer(\n",
              "      (embeddings): Embedding(90, 64)\n",
              "    )\n",
              "  )\n",
              "  (cls_token): CLSToken()\n",
              "  (transformer): Transformer(\n",
              "    (blocks): ModuleList(\n",
              "      (0): ModuleDict(\n",
              "        (attention): MultiheadAttention(\n",
              "          (W_q): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (W_k): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (W_v): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (W_out): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (dropout): Dropout(p=0.1971837206675287, inplace=False)\n",
              "        )\n",
              "        (ffn): FFN(\n",
              "          (linear_first): Linear(in_features=64, out_features=1024, bias=True)\n",
              "          (activation): ReGLU()\n",
              "          (dropout): Dropout(p=0.1971837206675287, inplace=False)\n",
              "          (linear_second): Linear(in_features=512, out_features=64, bias=True)\n",
              "        )\n",
              "        (attention_residual_dropout): Dropout(p=0.1971837206675287, inplace=False)\n",
              "        (ffn_residual_dropout): Dropout(p=0.1971837206675287, inplace=False)\n",
              "        (output): Identity()\n",
              "        (ffn_normalization): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (1-3): 3 x ModuleDict(\n",
              "        (attention): MultiheadAttention(\n",
              "          (W_q): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (W_k): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (W_v): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (W_out): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (dropout): Dropout(p=0.1971837206675287, inplace=False)\n",
              "        )\n",
              "        (ffn): FFN(\n",
              "          (linear_first): Linear(in_features=64, out_features=1024, bias=True)\n",
              "          (activation): ReGLU()\n",
              "          (dropout): Dropout(p=0.1971837206675287, inplace=False)\n",
              "          (linear_second): Linear(in_features=512, out_features=64, bias=True)\n",
              "        )\n",
              "        (attention_residual_dropout): Dropout(p=0.1971837206675287, inplace=False)\n",
              "        (ffn_residual_dropout): Dropout(p=0.1971837206675287, inplace=False)\n",
              "        (output): Identity()\n",
              "        (attention_normalization): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        (ffn_normalization): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (head): Head(\n",
              "      (normalization): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "      (activation): ReLU()\n",
              "      (linear): Linear(in_features=64, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from rtdl import FTTransformer\n",
        "from torch.serialization import safe_globals\n",
        "import torch\n",
        "\n",
        "# ‚úÖ Îç∞Ïù¥ÌÑ∞ Î°úÎî©\n",
        "with open(\"ADV&VIF_split_data_fn_transformer.pkl\", \"rb\") as f:\n",
        "    X_train_adv, X_valid_tensor, X_test_adv, y_train_tensor, y_valid_tensor, y_test_tensor = pickle.load(f)\n",
        "\n",
        "with safe_globals([FTTransformer]):\n",
        "    ft_model = torch.load(\"ADV_fttransformer_trained.pt\", weights_only=False, map_location=torch.device(\"cpu\"))\n",
        "ft_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo8R5c-3g4iJ",
        "outputId": "46aa81a3-c425-4fc0-e068-b87dafa3a081"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä FTTransformer ÌèâÍ∞Ä Í≤∞Í≥º (Ï†ÅÎåÄÏ†Å ÌõàÎ†® Í∏∞Î∞ò)\n",
            "MSE:   2,635,335,467,008.00\n",
            "RMSE:  1,623,371.64\n",
            "MAE:   427,002.44\n",
            "SMAPE: 142.6570%\n",
            "R¬≤:    0.63123\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# ‚úÖ SMAPE Ìï®Ïàò Ï†ïÏùò\n",
        "def smape(y_true, y_pred):\n",
        "    y_true = np.ravel(y_true)\n",
        "    y_pred = np.ravel(y_pred)\n",
        "\n",
        "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
        "    diff = np.abs(y_true - y_pred) / denominator\n",
        "    diff[denominator == 0] = 0.0\n",
        "    return 100 * np.mean(diff)\n",
        "\n",
        "# ‚úÖ Ïó≠Ï†ïÍ∑úÌôî Í∏∞Ï§Ä\n",
        "y_min = 216.0\n",
        "y_max = 165300000.0\n",
        "\n",
        "# ‚úÖ ÏòàÏ∏°\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "ft_model.to(device)\n",
        "ft_model.eval()\n",
        "preds = []\n",
        "\n",
        "cat_indices = list(range(X_test_tensor.shape[1]))\n",
        "batch_size = 1024\n",
        "n_samples = X_test_tensor.size(0)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(0, n_samples, batch_size):\n",
        "        xb = X_test_tensor[i:i+batch_size].to(device)\n",
        "        x_cat = xb[:, cat_indices].long()\n",
        "        pred = ft_model(None, x_cat)\n",
        "        preds.append(pred.cpu().numpy())\n",
        "\n",
        "\n",
        "# ‚úÖ Ïó∞Í≤∞ Î∞è Ïó≠Ï†ïÍ∑úÌôî\n",
        "y_pred = np.concatenate(preds).squeeze()\n",
        "y_true = y_test_tensor.cpu().numpy().squeeze()\n",
        "\n",
        "y_pred_inv = y_pred * (y_max - y_min) + y_min\n",
        "y_true_inv = y_true * (y_max - y_min) + y_min\n",
        "\n",
        "# ‚úÖ ÏÑ±Îä• ÏßÄÌëú Í≥ÑÏÇ∞\n",
        "mse = mean_squared_error(y_true_inv, y_pred_inv)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_true_inv, y_pred_inv)\n",
        "smp = smape(y_true_inv, y_pred_inv)\n",
        "r2 = r2_score(y_true_inv, y_pred_inv)\n",
        "\n",
        "# ‚úÖ Ï∂úÎ†•\n",
        "print(\"\\nüìä FTTransformer ÌèâÍ∞Ä Í≤∞Í≥º (Ï†ÅÎåÄÏ†Å ÌõàÎ†® Í∏∞Î∞ò)\")\n",
        "print(f\"MSE:   {mse:,.2f}\")\n",
        "print(f\"RMSE:  {rmse:,.2f}\")\n",
        "print(f\"MAE:   {mae:,.2f}\")\n",
        "print(f\"SMAPE: {smp:,.4f}%\")\n",
        "print(f\"R¬≤:    {r2:.5f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2riAgipicQO",
        "outputId": "cbf728d3-3eb3-49cb-f01b-81eda5968baa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ ÏÑ±Îä• ÏßÄÌëú Ï†ÄÏû• ÏôÑÎ£å ‚Üí adv_fttransforemr_results.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ‚úÖ Ï†ÄÏû•Ìï† ÏßÄÌëú Ï†ïÎ¶¨\n",
        "result_df = pd.DataFrame([{\n",
        "    \"Model\": \"FTTransformer_ADV\",  # ÏõêÌïòÎäî Î™®Îç∏Î™Ö ÏßÄÏ†ï\n",
        "    \"MSE\": mse,\n",
        "    \"RMSE\": rmse,\n",
        "    \"MAE\": mae,\n",
        "    \"SMAPE\": smp,\n",
        "    \"R2\": r2\n",
        "}])\n",
        "\n",
        "\n",
        "# ‚úÖ CSV Ï†ÄÏû•\n",
        "save_path = \"adv_fttransforemr_results.csv\"\n",
        "result_df.to_csv(save_path, index=False)\n",
        "\n",
        "print(f\"üìÅ ÏÑ±Îä• ÏßÄÌëú Ï†ÄÏû• ÏôÑÎ£å ‚Üí {save_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
